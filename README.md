# Signal Equalizer

A full-stack audio equalizer application with real-time visualization, multiple preset modes, and **AI-powered source separation**.

> **ðŸŽµ NEW in Phase 6**: AI Source Separation using Hybrid Demucs! Separate any song into drums, bass, vocals, and other instruments. [See docs](./docs/PHASE6_AI_INTEGRATION.md)

## Architecture

This is a monorepo containing:
- **Frontend**: React + TypeScript + Vite web application
- **Backend**: Python FastAPI server with Hybrid Demucs AI model for audio source separation

## Features

- **Audio File Loading**: Load and play various audio formats
- **Real-time Equalization**: Multiple EQ modes with STFT-based processing
- **ðŸŽµ AI Source Separation**: NEW! Separate music into drums, bass, vocals, and other using Hybrid Demucs
- **Equalizer Modes**:
  - **Preset Modes**: Three optimized presets (Musical, Animals, Voices)
  - **Generic Mode**: User-defined frequency subdivisions with linear gain control [0-2x]
  - **Customized Modes**: Advanced multi-window sliders for complex EQ curves (Musical Instruments, Human Voices)
- **Dual Linked Viewers**: Synchronized input/output waveform visualization
  - **Shared Pan/Zoom**: Both viewers zoom and pan together
  - **Time Cursor Sync**: Unified playback position indicator across both waveforms
  - **Reset View**: Quickly return to full waveform display
- **Advanced Playback Controls**: 
  - Play, pause, stop, and seek functionality
  - **Variable Speed**: Adjust playback rate from 0.5Ã— to 2Ã— without pitch change
  - Real-time cursor updates via subscription system
- **Spectrograms**: Input/Output time-frequency analysis + AI-generated spectrograms
- **Accessibility**: Full keyboard navigation, ARIA labels, and disabled states

## Project Structure

```
signal_equalizer/
â”œâ”€â”€ frontend/                  # React + TypeScript Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ FileLoader.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ BandsList.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ GenericMode.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CustomizedModePanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ LinkedWaveformViewers.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ WaveformViewer.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SpectrogramPanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Controls.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ModeSelector.tsx
â”‚   â”‚   â”‚   â””â”€â”€ AISourceSeparation.tsx  # NEW: AI separation UI
â”‚   â”‚   â”œâ”€â”€ lib/              # Core DSP algorithms
â”‚   â”‚   â”‚   â”œâ”€â”€ fft.ts        # Fast Fourier Transform
â”‚   â”‚   â”‚   â”œâ”€â”€ stft.ts       # Short-Time Fourier Transform
â”‚   â”‚   â”‚   â”œâ”€â”€ playback.ts   # Audio playback engine
â”‚   â”‚   â”‚   â”œâ”€â”€ spectrogram.ts # Spectrogram generation
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts        # NEW: Backend API client
â”‚   â”‚   â”‚   â””â”€â”€ modes.ts      # Mode management
â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”‚   â””â”€â”€ types.ts      # TypeScript type definitions
â”‚   â”‚   â””â”€â”€ App.tsx           # Main application
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ modes/            # EQ mode presets (JSON)
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ backend/                   # Python FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPI application + AI endpoints
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ demucs_service.py  # NEW: Hybrid Demucs AI service
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ test_main.py      # API tests
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies (includes PyTorch)
â”‚   â”œâ”€â”€ hybrid_demucs_tutorial.ipynb  # Reference notebook
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ PHASE4_IMPLEMENTATION.md
â”‚   â”œâ”€â”€ PHASE5_IMPLEMENTATION.md
â”‚   â””â”€â”€ PHASE6_AI_INTEGRATION.md  # NEW: AI integration docs
â”œâ”€â”€ test_assets/               # Test files
â””â”€â”€ README.md                  # This file
```

## Technology Stack

### Frontend
- **React 18**: UI framework
- **TypeScript**: Type-safe development
- **Vite**: Build tool and dev server
- **Web Audio API**: Audio processing and playback
- **HTML5 Canvas**: Audio visualizations
- **Vitest**: Testing framework

### Backend
- **Python 3.11+**: Programming language
- **FastAPI**: Modern async web framework
- **Uvicorn**: ASGI server
- **NumPy & SciPy**: Scientific computing
- **PyTorch & TorchAudio**: Deep learning for AI source separation
- **Hybrid Demucs**: State-of-the-art music source separation model
- **Matplotlib**: Spectrogram generation
- **Pytest**: Testing framework

## Getting Started

### Prerequisites

- **Frontend**: Node.js 16+ and npm
- **Backend**: Python 3.11+

### Installation & Running

#### Frontend

```bash
cd frontend
npm install
npm run dev
```

Frontend will be available at `http://localhost:5173`

#### Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python -m app.main
```

Backend API will be available at `http://localhost:8000`
- API Docs: `http://localhost:8000/docs`

### Build

#### Frontend Production Build

```bash
cd frontend
npm run build
npm run preview
```

#### Backend Production

```bash
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

## Development

### Frontend Testing

```bash
cd frontend
npm test              # Run tests once
npm run test:watch    # Watch mode
```

### Backend Testing

```bash
cd backend
pytest                           # Run tests
pytest --cov=app tests/         # With coverage
```

### Code Quality

#### Frontend
```bash
cd frontend
npm run lint
```

#### Backend
```bash
cd backend
black app/ tests/     # Format
flake8 app/ tests/    # Lint
mypy app/             # Type check
```

## Usage

1. **Load Audio**: Click "Load Audio File" and select an audio file
2. **Choose Mode**: 
   - **Preset Modes**: Select Musical, Animals, or Voices
   - **Generic Mode**: Define custom frequency subdivisions (add/delete/adjust bands)
   - **Customized Modes**: Use advanced multi-window sliders for Musical Instruments or Human Voices
3. **Adjust Bands**: Fine-tune frequency bands using the sliders (0-2x linear gain)
4. **Import/Export**: Save and load Generic Mode configurations via JSON
5. **Playback Controls**: 
   - Play/pause/stop to control audio playback
   - Adjust **playback speed** (0.5Ã—, 0.75Ã—, 1Ã—, 1.25Ã—, 1.5Ã—, 2Ã—) for detailed analysis
   - Seek through the audio timeline
6. **Synchronized Visualization**: 
   - Both input and output waveforms **zoom and pan together**
   - Watch the synchronized **time cursor** move across both viewers
   - Click **Reset View** to return to full waveform display
7. **Spectrograms**: Compare input/output time-frequency representations

## Technical Details

### Equalizer Implementation

- **Processing Method**: STFT-based frequency domain equalization
- **Filter Type**: Linear gain scaling (0-2x) applied to frequency bins
- **Window**: Hann window for STFT analysis/synthesis
- **Window Size**: 2048 samples
- **Hop Size**: 512 samples (75% overlap)
- **Reconstruction**: Windowed Overlap-Add (WOLA) method
- **Gain Vector**: Product-of-scales rule for overlapping frequency bands

### FFT/STFT

- **Algorithm**: Cooley-Tukey FFT (recursive, radix-2)
- **IFFT**: Conjugation method: `ifft(X) = (1/N) * conj(fft(conj(X)))`
- **Window**: Hann window cached for efficiency
- **Power-of-2 Enforcement**: Automatic zero-padding if needed

### Spectrogram

- **Color Map**: Blue to red intensity mapping
- **Dynamic Range**: 80 dB
- **Frequency Range**: 0 Hz to Nyquist (sample rate / 2)
- **Dual Display**: Input (original) and Output (EQ applied) side-by-side

### Dual Linked Viewers (Phase 5)

- **Architecture**: `LinkedWaveformViewers` wrapper component manages shared state
- **View Range**: Time-based API (seconds) for resolution independence
- **Pan/Zoom Sync**: Single `WaveformViewRange` state controls both viewers
- **Cursor Synchronization**: Subscription-based updates using `requestAnimationFrame`
- **Playback Rate**: Web Audio API's native `sourceNode.playbackRate` for pitch-preserved speed control
- **Performance**: `useCallback`/`useMemo` optimizations to minimize re-renders

### Multi-Window Bands

Customized modes support non-contiguous frequency ranges (e.g., Guitar spanning 82-330, 660-1320, 2640-5280 Hz) controlled by a single slider. See `docs/PHASE4_IMPLEMENTATION.md` for architecture details.

## Testing

### Frontend Tests
```bash
cd frontend
npm test
```

**Test Coverage** (73 passing tests):
- **FFT/IFFT**: Round-trip validation (3 tests)
- **STFT/ISTFT**: WOLA reconstruction (3 tests)
- **Gain Vector**: Multi-window support (2 tests)
- **Generic Mode**: Import/export validation (22 tests)
- **Customized Mode**: Loader and schema validation (16 tests)
- **Playback (Phase 5)**: Subscription system, playback rate control (18 tests)
- **Linked Viewers (Phase 5)**: Shared state, zoom sync, cursor sync (9 tests)

### Backend Tests
```bash
cd backend
pytest
```

Test audio files are included in `/test_assets` for validating import/export functionality.

## Documentation

See [comparison.md](comparison.md) for a detailed comparison of the equalizer modes and usage recommendations.

## License

MIT

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.